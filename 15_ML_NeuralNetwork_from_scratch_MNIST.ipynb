{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_ML_NeuralNetwork_from_scratch_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOARjJiWQ3Vxl50NH6Nb9+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cychen116/DataAnalysis_practice/blob/main/15_ML_NeuralNetwork_from_scratch_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HRJY9JO1vhxA"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Functions"
      ],
      "metadata": {
        "id": "VSe-FfLnvxdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base class\n",
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    # computes the output Y of a layer for a given input X\n",
        "    def forward_propagation(self, input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "ikNyMQsGvsUW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCLayer(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "      self.weights = np.random.rand(input_size, output_size) - 0.5\n",
        "      self.bias = np.random.rand(1, output_size) - 0.5\n",
        "    \n",
        "    def forward_propagation(self,input_data):\n",
        "      self.input = input_data\n",
        "      self.output = np.dot(self.input,self.weights)+self.bias\n",
        "      return(self.output)\n",
        "\n",
        "    ## compute dE/dw, de/dB for a given outputt erroor. Returns input error to be given t the next layer\n",
        "    def backward_propagation(self,output_error, learning_rate):\n",
        "      input_error = np.dot(output_error, self.weights.T)\n",
        "      weights_error = np.dot(self.input.T, output_error)\n",
        "\n",
        "      self.weights -= learning_rate * weights_error\n",
        "      self.bias -= learning_rate * output_error\n",
        "      return(input_error)"
      ],
      "metadata": {
        "id": "MG3X5PRkvwe8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationLayer(Layer):\n",
        "    def __init__(self):\n",
        "      self.activation = lambda x: np.tanh(x)  #over sigoma, tanh pi*0.25, which provide strong peak, cleaner and easier to compute\n",
        "      self.activation_prime = lambda x: 1-np.tanh(x)**2;\n",
        "    \n",
        "    def forward_propagation(self, input_data):\n",
        "      self.input = input_data\n",
        "      self.output = self.activation(self.input)\n",
        "      return(self.output)\n",
        "    \n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "      return(self.activation_prime(self.input) * output_error)"
      ],
      "metadata": {
        "id": "JloArTkiv1S6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function and its derivative\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2));\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2*(y_pred-y_true)/y_true.size;"
      ],
      "metadata": {
        "id": "5TZTY9gZv3en"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "  def __init__(self):\n",
        "    self.layers=[]\n",
        "    self.loss=None\n",
        "    self.loss_prime=None\n",
        "\n",
        "  def add(self,layer):\n",
        "    self.layers.append(layer)\n",
        "\n",
        "  def use(self,loss,loss_prime):\n",
        "    self.loss = loss\n",
        "    self.loss_prime = loss_prime\n",
        "\n",
        "  def predict(self,input_data):\n",
        "    result=[]\n",
        "    for i in range(len(input_data)):\n",
        "      output=input_data[i]\n",
        "      for layer in self.layers:\n",
        "        output= layer.forward_propagation(output)\n",
        "      result.append(output)\n",
        "    return(result)\n",
        "\n",
        "  def fit(self, x_train, y_train, epochs, learning_rate):\n",
        "    samples = len(x_train)\n",
        "    errors=[]\n",
        "\n",
        "    for i in range(epochs):\n",
        "      err = 0\n",
        "      for j in range(samples):\n",
        "        output = x_train[j]\n",
        "        for layer in self.layers:\n",
        "          output = layer.forward_propagation(output)\n",
        "        #print(y_train[j].shape, output.shape)\n",
        "        err += self.loss(y_train[j], output)\n",
        "\n",
        "        error = self.loss_prime(y_train[j], output)\n",
        "        for layer in reversed(self.layers):\n",
        "          error = layer.backward_propagation(error, learning_rate)\n",
        "      errors.append(err/samples)\n",
        "\n",
        "      print('epoch %d/%d   error=%f' % (i+1, epochs, err))\n",
        "    return(errors)"
      ],
      "metadata": {
        "id": "DlZ-1ux4v-Bq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Functions"
      ],
      "metadata": {
        "id": "cbQKeoZ5wFw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
        "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])"
      ],
      "metadata": {
        "id": "8XogxpeCwAJH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network()\n",
        "net.add(FCLayer(2,5))\n",
        "net.add(ActivationLayer())\n",
        "net.add(FCLayer(5,1))\n",
        "net.add(ActivationLayer())\n",
        "net.use(mse, mse_prime)"
      ],
      "metadata": {
        "id": "a4Xqis-nwIdq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err = net.fit(x_train, y_train, epochs=300, learning_rate=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10CtDOCjwJ7Y",
        "outputId": "59e7ac86-e74a-47e0-c957-732239a9aa6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/300   error=1.883896\n",
            "epoch 2/300   error=1.410552\n",
            "epoch 3/300   error=1.345683\n",
            "epoch 4/300   error=1.326607\n",
            "epoch 5/300   error=1.316765\n",
            "epoch 6/300   error=1.309700\n",
            "epoch 7/300   error=1.303687\n",
            "epoch 8/300   error=1.298166\n",
            "epoch 9/300   error=1.292938\n",
            "epoch 10/300   error=1.287927\n",
            "epoch 11/300   error=1.283102\n",
            "epoch 12/300   error=1.278446\n",
            "epoch 13/300   error=1.273950\n",
            "epoch 14/300   error=1.269606\n",
            "epoch 15/300   error=1.265409\n",
            "epoch 16/300   error=1.261353\n",
            "epoch 17/300   error=1.257431\n",
            "epoch 18/300   error=1.253639\n",
            "epoch 19/300   error=1.249972\n",
            "epoch 20/300   error=1.246426\n",
            "epoch 21/300   error=1.242996\n",
            "epoch 22/300   error=1.239678\n",
            "epoch 23/300   error=1.236469\n",
            "epoch 24/300   error=1.233366\n",
            "epoch 25/300   error=1.230366\n",
            "epoch 26/300   error=1.227464\n",
            "epoch 27/300   error=1.224660\n",
            "epoch 28/300   error=1.221950\n",
            "epoch 29/300   error=1.219332\n",
            "epoch 30/300   error=1.216803\n",
            "epoch 31/300   error=1.214362\n",
            "epoch 32/300   error=1.212005\n",
            "epoch 33/300   error=1.209731\n",
            "epoch 34/300   error=1.207538\n",
            "epoch 35/300   error=1.205424\n",
            "epoch 36/300   error=1.203386\n",
            "epoch 37/300   error=1.201423\n",
            "epoch 38/300   error=1.199532\n",
            "epoch 39/300   error=1.197711\n",
            "epoch 40/300   error=1.195958\n",
            "epoch 41/300   error=1.194272\n",
            "epoch 42/300   error=1.192649\n",
            "epoch 43/300   error=1.191089\n",
            "epoch 44/300   error=1.189588\n",
            "epoch 45/300   error=1.188145\n",
            "epoch 46/300   error=1.186758\n",
            "epoch 47/300   error=1.185425\n",
            "epoch 48/300   error=1.184143\n",
            "epoch 49/300   error=1.182912\n",
            "epoch 50/300   error=1.181728\n",
            "epoch 51/300   error=1.180590\n",
            "epoch 52/300   error=1.179497\n",
            "epoch 53/300   error=1.178445\n",
            "epoch 54/300   error=1.177434\n",
            "epoch 55/300   error=1.176461\n",
            "epoch 56/300   error=1.175525\n",
            "epoch 57/300   error=1.174623\n",
            "epoch 58/300   error=1.173755\n",
            "epoch 59/300   error=1.172918\n",
            "epoch 60/300   error=1.172111\n",
            "epoch 61/300   error=1.171332\n",
            "epoch 62/300   error=1.170580\n",
            "epoch 63/300   error=1.169852\n",
            "epoch 64/300   error=1.169147\n",
            "epoch 65/300   error=1.168463\n",
            "epoch 66/300   error=1.167799\n",
            "epoch 67/300   error=1.167153\n",
            "epoch 68/300   error=1.166524\n",
            "epoch 69/300   error=1.165909\n",
            "epoch 70/300   error=1.165307\n",
            "epoch 71/300   error=1.164717\n",
            "epoch 72/300   error=1.164136\n",
            "epoch 73/300   error=1.163563\n",
            "epoch 74/300   error=1.162996\n",
            "epoch 75/300   error=1.162433\n",
            "epoch 76/300   error=1.161872\n",
            "epoch 77/300   error=1.161312\n",
            "epoch 78/300   error=1.160749\n",
            "epoch 79/300   error=1.160182\n",
            "epoch 80/300   error=1.159609\n",
            "epoch 81/300   error=1.159027\n",
            "epoch 82/300   error=1.158433\n",
            "epoch 83/300   error=1.157825\n",
            "epoch 84/300   error=1.157200\n",
            "epoch 85/300   error=1.156556\n",
            "epoch 86/300   error=1.155888\n",
            "epoch 87/300   error=1.155193\n",
            "epoch 88/300   error=1.154468\n",
            "epoch 89/300   error=1.153710\n",
            "epoch 90/300   error=1.152912\n",
            "epoch 91/300   error=1.152072\n",
            "epoch 92/300   error=1.151185\n",
            "epoch 93/300   error=1.150245\n",
            "epoch 94/300   error=1.149247\n",
            "epoch 95/300   error=1.148186\n",
            "epoch 96/300   error=1.147054\n",
            "epoch 97/300   error=1.145846\n",
            "epoch 98/300   error=1.144555\n",
            "epoch 99/300   error=1.143172\n",
            "epoch 100/300   error=1.141690\n",
            "epoch 101/300   error=1.140101\n",
            "epoch 102/300   error=1.138395\n",
            "epoch 103/300   error=1.136562\n",
            "epoch 104/300   error=1.134593\n",
            "epoch 105/300   error=1.132477\n",
            "epoch 106/300   error=1.130202\n",
            "epoch 107/300   error=1.127757\n",
            "epoch 108/300   error=1.125128\n",
            "epoch 109/300   error=1.122303\n",
            "epoch 110/300   error=1.119268\n",
            "epoch 111/300   error=1.116008\n",
            "epoch 112/300   error=1.112507\n",
            "epoch 113/300   error=1.108752\n",
            "epoch 114/300   error=1.104724\n",
            "epoch 115/300   error=1.100407\n",
            "epoch 116/300   error=1.095784\n",
            "epoch 117/300   error=1.090836\n",
            "epoch 118/300   error=1.085546\n",
            "epoch 119/300   error=1.079894\n",
            "epoch 120/300   error=1.073862\n",
            "epoch 121/300   error=1.067430\n",
            "epoch 122/300   error=1.060580\n",
            "epoch 123/300   error=1.053293\n",
            "epoch 124/300   error=1.045549\n",
            "epoch 125/300   error=1.037333\n",
            "epoch 126/300   error=1.028628\n",
            "epoch 127/300   error=1.019418\n",
            "epoch 128/300   error=1.009691\n",
            "epoch 129/300   error=0.999436\n",
            "epoch 130/300   error=0.988645\n",
            "epoch 131/300   error=0.977314\n",
            "epoch 132/300   error=0.965442\n",
            "epoch 133/300   error=0.953031\n",
            "epoch 134/300   error=0.940088\n",
            "epoch 135/300   error=0.926623\n",
            "epoch 136/300   error=0.912651\n",
            "epoch 137/300   error=0.898189\n",
            "epoch 138/300   error=0.883258\n",
            "epoch 139/300   error=0.867879\n",
            "epoch 140/300   error=0.852074\n",
            "epoch 141/300   error=0.835864\n",
            "epoch 142/300   error=0.819270\n",
            "epoch 143/300   error=0.802308\n",
            "epoch 144/300   error=0.784991\n",
            "epoch 145/300   error=0.767330\n",
            "epoch 146/300   error=0.749327\n",
            "epoch 147/300   error=0.730983\n",
            "epoch 148/300   error=0.712296\n",
            "epoch 149/300   error=0.693258\n",
            "epoch 150/300   error=0.673862\n",
            "epoch 151/300   error=0.654100\n",
            "epoch 152/300   error=0.633966\n",
            "epoch 153/300   error=0.613461\n",
            "epoch 154/300   error=0.592590\n",
            "epoch 155/300   error=0.571366\n",
            "epoch 156/300   error=0.549815\n",
            "epoch 157/300   error=0.527975\n",
            "epoch 158/300   error=0.505898\n",
            "epoch 159/300   error=0.483650\n",
            "epoch 160/300   error=0.461310\n",
            "epoch 161/300   error=0.438973\n",
            "epoch 162/300   error=0.416743\n",
            "epoch 163/300   error=0.394733\n",
            "epoch 164/300   error=0.373059\n",
            "epoch 165/300   error=0.351839\n",
            "epoch 166/300   error=0.331189\n",
            "epoch 167/300   error=0.311213\n",
            "epoch 168/300   error=0.292005\n",
            "epoch 169/300   error=0.273644\n",
            "epoch 170/300   error=0.256191\n",
            "epoch 171/300   error=0.239689\n",
            "epoch 172/300   error=0.224162\n",
            "epoch 173/300   error=0.209616\n",
            "epoch 174/300   error=0.196042\n",
            "epoch 175/300   error=0.183418\n",
            "epoch 176/300   error=0.171709\n",
            "epoch 177/300   error=0.160874\n",
            "epoch 178/300   error=0.150865\n",
            "epoch 179/300   error=0.141631\n",
            "epoch 180/300   error=0.133119\n",
            "epoch 181/300   error=0.125277\n",
            "epoch 182/300   error=0.118053\n",
            "epoch 183/300   error=0.111397\n",
            "epoch 184/300   error=0.105262\n",
            "epoch 185/300   error=0.099603\n",
            "epoch 186/300   error=0.094380\n",
            "epoch 187/300   error=0.089554\n",
            "epoch 188/300   error=0.085090\n",
            "epoch 189/300   error=0.080957\n",
            "epoch 190/300   error=0.077125\n",
            "epoch 191/300   error=0.073568\n",
            "epoch 192/300   error=0.070261\n",
            "epoch 193/300   error=0.067184\n",
            "epoch 194/300   error=0.064316\n",
            "epoch 195/300   error=0.061640\n",
            "epoch 196/300   error=0.059139\n",
            "epoch 197/300   error=0.056800\n",
            "epoch 198/300   error=0.054607\n",
            "epoch 199/300   error=0.052551\n",
            "epoch 200/300   error=0.050619\n",
            "epoch 201/300   error=0.048802\n",
            "epoch 202/300   error=0.047092\n",
            "epoch 203/300   error=0.045479\n",
            "epoch 204/300   error=0.043957\n",
            "epoch 205/300   error=0.042519\n",
            "epoch 206/300   error=0.041159\n",
            "epoch 207/300   error=0.039871\n",
            "epoch 208/300   error=0.038650\n",
            "epoch 209/300   error=0.037492\n",
            "epoch 210/300   error=0.036391\n",
            "epoch 211/300   error=0.035346\n",
            "epoch 212/300   error=0.034350\n",
            "epoch 213/300   error=0.033402\n",
            "epoch 214/300   error=0.032499\n",
            "epoch 215/300   error=0.031637\n",
            "epoch 216/300   error=0.030813\n",
            "epoch 217/300   error=0.030027\n",
            "epoch 218/300   error=0.029275\n",
            "epoch 219/300   error=0.028555\n",
            "epoch 220/300   error=0.027865\n",
            "epoch 221/300   error=0.027204\n",
            "epoch 222/300   error=0.026570\n",
            "epoch 223/300   error=0.025962\n",
            "epoch 224/300   error=0.025377\n",
            "epoch 225/300   error=0.024816\n",
            "epoch 226/300   error=0.024276\n",
            "epoch 227/300   error=0.023756\n",
            "epoch 228/300   error=0.023256\n",
            "epoch 229/300   error=0.022774\n",
            "epoch 230/300   error=0.022309\n",
            "epoch 231/300   error=0.021861\n",
            "epoch 232/300   error=0.021429\n",
            "epoch 233/300   error=0.021012\n",
            "epoch 234/300   error=0.020609\n",
            "epoch 235/300   error=0.020219\n",
            "epoch 236/300   error=0.019843\n",
            "epoch 237/300   error=0.019479\n",
            "epoch 238/300   error=0.019126\n",
            "epoch 239/300   error=0.018785\n",
            "epoch 240/300   error=0.018455\n",
            "epoch 241/300   error=0.018135\n",
            "epoch 242/300   error=0.017824\n",
            "epoch 243/300   error=0.017524\n",
            "epoch 244/300   error=0.017232\n",
            "epoch 245/300   error=0.016948\n",
            "epoch 246/300   error=0.016673\n",
            "epoch 247/300   error=0.016406\n",
            "epoch 248/300   error=0.016147\n",
            "epoch 249/300   error=0.015895\n",
            "epoch 250/300   error=0.015649\n",
            "epoch 251/300   error=0.015411\n",
            "epoch 252/300   error=0.015179\n",
            "epoch 253/300   error=0.014953\n",
            "epoch 254/300   error=0.014734\n",
            "epoch 255/300   error=0.014520\n",
            "epoch 256/300   error=0.014311\n",
            "epoch 257/300   error=0.014108\n",
            "epoch 258/300   error=0.013910\n",
            "epoch 259/300   error=0.013718\n",
            "epoch 260/300   error=0.013529\n",
            "epoch 261/300   error=0.013346\n",
            "epoch 262/300   error=0.013167\n",
            "epoch 263/300   error=0.012992\n",
            "epoch 264/300   error=0.012822\n",
            "epoch 265/300   error=0.012655\n",
            "epoch 266/300   error=0.012493\n",
            "epoch 267/300   error=0.012334\n",
            "epoch 268/300   error=0.012179\n",
            "epoch 269/300   error=0.012027\n",
            "epoch 270/300   error=0.011879\n",
            "epoch 271/300   error=0.011734\n",
            "epoch 272/300   error=0.011592\n",
            "epoch 273/300   error=0.011453\n",
            "epoch 274/300   error=0.011317\n",
            "epoch 275/300   error=0.011185\n",
            "epoch 276/300   error=0.011055\n",
            "epoch 277/300   error=0.010927\n",
            "epoch 278/300   error=0.010803\n",
            "epoch 279/300   error=0.010681\n",
            "epoch 280/300   error=0.010561\n",
            "epoch 281/300   error=0.010444\n",
            "epoch 282/300   error=0.010330\n",
            "epoch 283/300   error=0.010217\n",
            "epoch 284/300   error=0.010107\n",
            "epoch 285/300   error=0.009999\n",
            "epoch 286/300   error=0.009893\n",
            "epoch 287/300   error=0.009789\n",
            "epoch 288/300   error=0.009687\n",
            "epoch 289/300   error=0.009587\n",
            "epoch 290/300   error=0.009489\n",
            "epoch 291/300   error=0.009392\n",
            "epoch 292/300   error=0.009298\n",
            "epoch 293/300   error=0.009205\n",
            "epoch 294/300   error=0.009114\n",
            "epoch 295/300   error=0.009025\n",
            "epoch 296/300   error=0.008937\n",
            "epoch 297/300   error=0.008850\n",
            "epoch 298/300   error=0.008766\n",
            "epoch 299/300   error=0.008682\n",
            "epoch 300/300   error=0.008601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(err).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "sUhyWGdMwLmy",
        "outputId": "7206a7fc-cde8-4785-de20-7d4f37cd935d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f04570fdb50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = net.predict(x_train)\n",
        "print(x_train, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuF4iFyEwPgA",
        "outputId": "f8cec6f3-8839-48ac-ebad-80a257e7c1ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0 0]]\n",
            "\n",
            " [[0 1]]\n",
            "\n",
            " [[1 0]]\n",
            "\n",
            " [[1 1]]] [array([[0.00725305]]), array([[0.93696663]]), array([[0.93374986]]), array([[-0.00497007]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digits Recognition"
      ],
      "metadata": {
        "id": "Kt8Rs4jPwS0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, 28*28).astype('float32')/255\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 28*28).astype('float32')/255\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2r1O2jvwRjc",
        "outputId": "f010bbf6-319f-4e30-e38e-934aab22312e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFbea6RPwdym",
        "outputId": "0b90f93d-efc9-47c0-b1d5-2365985641fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network()\n",
        "net.add(FCLayer(28*28, 100))\n",
        "net.add(ActivationLayer())\n",
        "net.add(FCLayer(100, 50)) \n",
        "net.add(ActivationLayer())\n",
        "net.add(FCLayer(50, 10)) \n",
        "net.add(ActivationLayer())\n",
        "net.use(mse, mse_prime)\n",
        "\n",
        "errors = net.fit(x_train[0:5000], y_train[0:5000], epochs=35, learning_rate=0.1) #sample the testing number, x_train[0:5000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5d2y1TtwgAE",
        "outputId": "416ea117-4054-492b-eea9-9adefa80eed2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/35   error=579.638632\n",
            "epoch 2/35   error=265.217903\n",
            "epoch 3/35   error=190.762111\n",
            "epoch 4/35   error=151.655848\n",
            "epoch 5/35   error=129.249735\n",
            "epoch 6/35   error=113.766096\n",
            "epoch 7/35   error=101.272831\n",
            "epoch 8/35   error=91.029008\n",
            "epoch 9/35   error=83.457401\n",
            "epoch 10/35   error=77.320805\n",
            "epoch 11/35   error=71.970475\n",
            "epoch 12/35   error=67.498914\n",
            "epoch 13/35   error=63.490929\n",
            "epoch 14/35   error=60.091839\n",
            "epoch 15/35   error=57.070446\n",
            "epoch 16/35   error=54.315229\n",
            "epoch 17/35   error=51.909331\n",
            "epoch 18/35   error=49.836703\n",
            "epoch 19/35   error=48.073710\n",
            "epoch 20/35   error=46.338833\n",
            "epoch 21/35   error=44.616273\n",
            "epoch 22/35   error=43.108176\n",
            "epoch 23/35   error=41.701015\n",
            "epoch 24/35   error=40.399548\n",
            "epoch 25/35   error=39.160012\n",
            "epoch 26/35   error=38.182511\n",
            "epoch 27/35   error=37.154948\n",
            "epoch 28/35   error=36.147427\n",
            "epoch 29/35   error=35.182141\n",
            "epoch 30/35   error=34.077603\n",
            "epoch 31/35   error=33.021662\n",
            "epoch 32/35   error=32.181918\n",
            "epoch 33/35   error=31.283176\n",
            "epoch 34/35   error=30.657725\n",
            "epoch 35/35   error=30.169793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(net.predict(x_test[:3]))\n",
        "print(y_test[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW4Zjcn6wigP",
        "outputId": "b1404c30-f252-4aa9-b0ae-d43611f53c88"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 6.09211269e-03, -2.17993050e-02,  9.50338938e-03,\n",
            "         2.15199518e-02,  3.66315133e-04,  1.26212955e-02,\n",
            "        -1.96558421e-02,  9.90136571e-01, -4.33053543e-02,\n",
            "        -2.17162265e-02]]), array([[-0.01099485, -0.00765838,  0.98306643,  0.03016832,  0.00973875,\n",
            "         0.03335497,  0.05912392, -0.0023395 , -0.2397076 , -0.00143443]]), array([[ 0.00632424,  0.98306759,  0.00560132,  0.01540759,  0.01715542,\n",
            "         0.01134257, -0.01704351, -0.00525591, -0.03709321, -0.04638728]])]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  out = sum((net.predict(x_test[i]) - y_test[i])[0][0])\n",
        "  print(out)\n",
        "  print(out<0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Y1iSY1wn4s",
        "outputId": "2020983d-e2af-409a-933d-3717ccf1d1fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.06623709248934702\n",
            "True\n",
            "-0.14668237518293537\n",
            "True\n",
            "-0.06688117255311343\n",
            "True\n",
            "-0.059676426178211325\n",
            "True\n",
            "0.06502103414947903\n",
            "True\n",
            "-0.07815682165510897\n",
            "True\n",
            "0.1086831453633655\n",
            "True\n",
            "0.07534861865339901\n",
            "True\n",
            "0.3566473961611921\n",
            "True\n",
            "-0.013777990532575862\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors=[]\n",
        "for i in range(1000):\n",
        "  out=sum((net.predict(x_test[i]) - y_test[i])[0][0])\n",
        "  errors.append(0 if out<0.5 else 1)"
      ],
      "metadata": {
        "id": "TGxZOTn_wpzb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hFqQbFxwrSq",
        "outputId": "18129da1-4be4-433c-ab6e-9d34040ba821"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8-BJWGkxxY0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}